[{"content":"Welcome to Dr Iggy’s coding adventures ","description":"","tags":null,"title":"Dr Iggy's Coding Adventures","uri":"/"},{"content":"","description":"","tags":null,"title":"memory","uri":"/tags/memory/"},{"content":"","description":"","tags":null,"title":"programming","uri":"/tags/programming/"},{"content":"Input-output being one of the most fundamental systems in any programming language was probably one of the first that was designed in Zig’s standard library. As Zig grew and gained additional features it had a few redesigns but it is still not without issues so here I want to analyze how it is currently implemented and if we can now do better.\nNote There are additional language improvement proposals aiming to improve this exact area like this and this but here I will only present what can be done with Zig today.\nCurrent Zig IO API We will start at the lowest level with std.fs.File representing a file on the file system and std.net.Stream representing a network stream. Both of these have the following methods:\n1 2 fn read(self, buffer: []u8) Error!u64 fn write(self, buffer: []const u8) Error!u64; They also have a close() method and methods to fetch their Reader and Writer objects which we will explain later. File also has a lot of other methods that only make sense for a File but not for a network stream. One set of such methods, that are of interest, are seeking methods and a method to fetch a SeekableStream from a File. They are:\n1 2 3 4 fn getEndPos(self: File) GetSeekPosError!u64; fn getPos(self: File) GetSeekPosError!u64; fn seekBy(self: File, offset: i64) SeekError!void; fn seekTo(self: File, offset: i64) SeekError!void; std.io.SeekableStream is a generic struct that contains a pointer to the original stream and those seekable methods that just call those same methods on that original stream. That way it acts as a sort of interface. File, of course, defines its own instance of this type so that the pointer in that instance is of type *File and same goes for std.net.Stream.\nReader and Writer std.io.Reader and std.io.Writer are also generic structs that contain a pointer to original stream but besides wrapping the read() and write() methods respectively they also provide additional methods, or, in other words, additional behavior. Some examples for Reader are:\n1 2 3 4 fn readByte(self: @This()) !u8; fn readInt(self: @This(), comptime T: type, endian: anytype) anytype; fn readStruct(self: @This(), comptime T: type) anytype; fn readUntilDelimiter(self: @This(), buf: []u8, delimiter: u8) ![]u8; And some examples for Writer are:\n1 2 3 fn print(self: @This(), comptime format: []const u8, args: anytype) anytype; fn writeByte(self: @This(), byte: u8) !void; fn writeByteNTimes(self: @This(), byte: u8, n: u64) !void So the Reader and Writer wrap an existing method and provide additional ones while SeekableStream only wraps existing methods.\nStreamSource When you write some kind of loaders or parsers you often want to support two ways of doing it. One way lets the user just specify the file from which to parse the data and another one allows the user to load the data themselves and then provide the buffer from which to parse.\nReading a buffer as a stream is provided by a std.io.FixedBufferStream which provides read(), write() and seek methods and methods to fetch the Reader, Writer and SeekableStream over that buffer.\nThat way if some loader function accepts any reader you can pass it either File.reader() or FixefBufferStream.reader() and it could work with both. Since those two readers are different type instances of a generic type that function would need to accept anytype and thus be generic itself. If it needs to store a reference to that reader then the entire type containing that function would need to be generic. That can lead to a lot of generated code.\nstd.io.StreamSource exists to solve that issue for the most common case I explained above. It is a union that can wrap either a buffer or a file and then provide one streaming API for both in the form of already described read(), write() and seek methods and methods to fetch the Reader, Writer and SeekableStream.\nWith it you can now write non generic loader functions that either accept the whole StreamSource or just StreamSource.Reader and they will support reading from either a file or memory buffer, but it will not, for example, support reading from std.net.Stream in any way.\nAnalysis File and std.net.Stream wrap the functionality offered by the operating systems with a simple and straightforward API so I don’t see some room for options there. Maybe some of the methods that currently only exist on File could make sense for std.net.Stream as well, like readAll and writeAll, but that is it.\nNow Reader, Writer and SeekableStream seem a bit odd. They look like interfaces but they are generic types, meaning each underlying stream that wants to provide them needs to define its own specific type of those generics. That in turn means that any methods that want to receive any Reader for example, would have to actually receive a parameter of type anytype and then just assume or check that that type has all the Reader methods it needs. Same goes for the other two interfaces.\nHaving SeekableStream as a separate struct doesn’t make sense from a usage point of view. You never just need a seeking functionality. You need it in combination with reading or writing. If some method needs a seekable reader it needs to receive anytype Reader and anytype SeekableStream. Two things that actually refer to the same underlying stream.\nCurrently std.io.BufferedReader is implemented in a way where it can wrap any other Reader and provide buffering additionally but if you then try to use it with a SeekableStream from the original stream it will not work. BufferedReader itself doesn’t provide a way to do the seeking.\nThe only reason I see that it is now separated is the fact that some streams support seeking, like File, while some like std.net.Stream don’t and there wasn’t an easy way to sometimes create a Reader with and sometimes without seeking methods. Same goes for the Writer.\nAnother oddity of SeekableStream is that it doesn’t add any additional behavior. As far as I see there is really no need for it at all in this form. If any method that needs a SeekableStream actually needs to receive anytype and then see if it has seek methods we can always just provide the original stream as a parameter since it will already have those methods. Currently they could be called differently in the original stream since they are actually passed as comptime parameters to generic SeekableStream struct but I saw no example where that was actually needed.\nAnother important problem of creating these Reader, Writer and SeekableStream abstractions over different types of streams is that those streams often return different error sets from their read(), write() and seek methods. Sometimes they don’t even return any error at all.\nThat is the main reason those abstractions need to remain generic. The only other option is to allow methods in abstractions to return anyerror and thus lose information about specific possible errors.\nAlternatives 1. Just make SeekableStream a part of Reader and Writer We can easily solve this with the help of mixins. If you don’t know what they are or how they work in Zig you can read my previous post.\nThe solution would look something like this for the Reader:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 pub fn ReaderMethods( comptime Self: type, comptime ReadError: type, comptime readFn: fn (context: Context, buffer: []u8) ReadError!usize, ) type { return struct { pub const Error = ReadError; pub fn read(self: Self, buffer: []u8) Error!usize { return readFn(self.context, buffer); } // The rest of the Reader methods }; } pub fn SeekMethods(comptime Self: type) type { return struct { pub const SeekError = getReturnErrorType(@TypeOf(self.context.seekBy)); pub const GetSeekPosError = getReturnErrorType(@TypeOf(self.context.getPos)); pub fn seekBy(self: Self, amt: i64) SeekError!void { return self.context.seekBy(amt); } // The rest of seek methods }; } pub fn Reader( comptime Context: type, comptime ReadError: type, comptime readFn: fn (context: Context, buffer: []u8) ReadError!usize, ) type { return struct { context: Context, const Self = @This(); pub usingnamespace ReaderMethods(Self, ReadError, readFn); // One option is to support seeking here directly if needed: pub usingnamespace if (hasSeekMethods(Context)) SeekMethods(Self) else struct {}; }; } // The other option is to provide explicit choice for SeekableReader: pub fn SeekableReader( comptime Context: type, comptime ReadError: type, comptime readFn: fn (context: Context, buffer: []u8) ReadError!usize, ) type { return struct { context: Context, const Self = @This(); pub usingnamespace ReaderMethods(Self, ReadError, readFn); pub usingnamespace SeekMethods(Self); }; } Note that I am not passing seek methods explicitly like SeekableStream currently does since, as I said, I didn’t find an example where they are called differently and can’t be used directly. If there are other reasons to do that then we would need to go with the second option and pass another six parameters that SeekableStream now receives.\nIf we don’t pass those methods we should probably add checks that Context does contain seek methods and report a nice @compileError if it doesn’t.\nCurrently BufferedReader is defined like this:\n1 pub fn BufferedReader(comptime buffer_size: usize, comptime ReaderType: type) type; Just like above we can make BufferedSeekMethods mixin and mix it in only if ReaderType has seek methods. That way if passed in ReaderType has seek methods so will its BufferedReader. That is one problem solved.\nAdditionally this would make it easy to write the StreamSource so that it wraps File.BufferedReader instead of File directly.\nAnother thing we can do is add something like this to the Reader:\n1 pub const readerInterfaceId = @typeName(Context) ++ \".Reader\"; If some method wants to check if the anytype parameter passed to it is a Reader it can just check if it @hasDecl(ReaderType, \"readerInterfaceId\") and the value of that field could maybe be used in some @compileError messages. SeekMethods mixin could additionally add another seekableIntefaceId so we can use the same method to check if it also has seek methods.\nThe other problems coming from these being generic types remain but they might be insignificant.\nMigrating the standard library and existing code to this solution shouldn’t be too hard. Mostly it would involve deleting SeekableStream and its usages and std lib isn’t using it anyway.\n2. Use VTable interface like Allocator Allocator is an interface to any concrete allocator implementation but it isn’t a generic type. It is a plain struct that contains an opaque pointer to the actual allocator and a vtable struct with pointers to internal wrapping methods that also receive an opaque pointer as first parameter. Some comptime magic is only used to generate those internal wrapping methods so they cast that first parameter to the type of each concrete allocator implementation before calling its own method.\nAllocator struct then also provides additional common utility methods that use some of the basic three that must be provided by the implementation: alloc, free and resize. So this method still allows adding additional behavior.\nNow all allocator implementations can only return one error from their alloc() method and that is OutOfMemory. That allows this single Allocator struct to have a wrapping method that also can return just this error and still be the common interface for any concrete implementation.\nAs already mentioned, different streams return different kinds of errors from their read, write and seek methods so the only way this pattern could work is if the common interfaces return anyerror. That also means that any library function that works with a Reader or Writer also needs to return anyerror thus losing the ability to document and help its user properly handle its specific errors.\nBecause of this issue with errors this solution is really not viable so there is no point in further analyzing it.\n3. Make streams be Readers and Writers using mixins Again if you don’t know what mixins are or how they are done in Zig you can read about it here.\nIn this approach there would not be a separate Reader, Writer and SeekableStream. There would just be ReaderMethods and WriterMethods mixins that provide that common additional methods that currently Reader and Writer provide. Something like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 pub fn ReaderMethods(comptime Self: type) type { // Now the provided Self type needs to provide the read method if (!@hasDecl(Self, \"read\")) { @compileError(\"Expected a read(*\" ++ @typeName(Self) ++ \", []const u8) !usize method in \" ++ @typeName(Self)); } const ReadError = getReturnErrorType(@TypeOf(Self.read)); if (@TypeOf(Self.read) != fn(*Self, []u8) ReadError!usize) { @compileError(\"Expected a read \" ++ @typeName(fn(*Self, []u8) ReadError!usize) ++ \" method in \" ++ @typeName(Self) ++ \" but got \" ++ @typeName(@TypeOf(Self.read))); } return struct { pub fn readAll(self: Self, buffer: []u8) Error!usize { var index: usize = 0; while (index != buffer.len) { const amt = try self.read(buffer[index..]); if (amt == 0) return index; index += amt; } return index; } // The rest of the Reader methods }; } File and std.net.Stream would now mixin those methods into their own implementation and File would still have those additional seeking methods. Functions that need to receive ‘some seekable reader’ for example, would provide one argument of type anytype and just like now check if all the methods needed, both reading and seeking, are defined on the given type.\nWe could use the trick I mentioned in the first alternative, where ReaderMethods also define\n1 pub const readerInterfaceId = @typeName(Self) ++ \".Reader\"; so that checking if some ReaderType: anytype is a reader can be done like this\n1 if (@hasDecl(ReaderType, \"readerInterfaceId\")) ... For that purpose we could also define SeekerMethods() mixin that only checks if the given Self type has all the seek methods and only mixes in\n1 pub const seekInterfaceId = @typeName(Self) ++ \".Seeker\"; and doesn’t add any new methods.\nBufferedReader would provide its own read() method that wraps the original one with additional logic just like now and would also mixin ReaderMethods. If the passed in reader has seek methods it could also wrap those using something like this:\n1 2 3 pub usingnamespace if (@hasDecl(ReaderType, \"seekInterfaceId\")) struct { // Seek methods go here } else struct {}; In this approach there is even less indirection than in the current implementation and it is also easy to implement and use. Methods that receive them as arguments being generic as in the current solution would also generate similar amounts of code.\nOne issue with this approach is that the struct that wants to use these mixins must have a read method with this exact signature:\n1 read(self: *Self, buffer: []u8) SomeError!usize Same goes for the write() method. Both File and std.net.Stream do have that but currently in std lib we also have:\nstd.fifo.LinearFifo which has a read method whose return type is just usize and not an error union and so for the current Reader it defines a separate method called readFn that just calls read but returns an error union with empty error set like this error{}!usize. std.os.uefi.protocols.FileProtocol that has a read method with a bit different signature and then it also defines a separate readFn method for the Reader that has the proper signature and marshals the call to the actual read. Note that the reason they must have a read() method that returns error union is not the check we added in ReaderMethods mixin but the fact that code that uses “any reader” might always call try reader.read(...) and the try statement will not compile unless read() returns an error union.\nI am not sure how acceptable it would be to change the main read() method in those structs to align with the Reader interface and then provide their current read() method under a different name.\nMigrating existing code to this alternative also wouldn’t be too hard and would mostly involve deleting code. We would need to delete all reader(), writer() and seekableStream() methods and probably just replace their calls with the object they were called on. For example:\n1 2 3 4 5 6 7 8 ImageLoader.load(someStream.reader()); // would just become ImageLoader.load(someStream); // and in case Image Loader was receiving StreamSource it would remain the same: ImageLoader.load(someStreamSource); StreamSource in this alternative would still wrap read(), write() and seek methods just like now and also mixin the ReadMethods, WriteMethods and SeekMethods.\nConclusion Only the second alternative turned out to be unusable but the analysis still helped us better understand why.\nThe first alternative that just merges SeekableStream into Reader and Writer seems to me like a clear improvement with no downsides over the existing solution.\nPersonally I like the third alternative the most. It gives the most potential for clearing up both the stream implementations and their usage code. I am just not sure how acceptable it is to require that every stream implements the exact read() and write() methods that are required by the interfaces.\nWhat do you think? Do you have some further arguments to provide over some solution? Or maybe you have an idea for some new solution? Join us on Ziggit forum and share your opinion.\n","description":"","tags":["zig","programming","memory"],"title":"Redesigning Zig IO Api","uri":"/blog/redesigning-zig-io-api/"},{"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/"},{"content":"","description":"","tags":null,"title":"zig","uri":"/tags/zig/"},{"content":"","description":"","tags":null,"title":"mixins","uri":"/tags/mixins/"},{"content":"What are mixins? Mixins are a way to mix in some common functionality into multiple structs. For example if you have a File and TcpSocket and they have their own different implementations of read(buffer: []u8) method and you want to add convenience methods like readInt(), readStruct() and similar that just call the read() method and format the result, you would usually have to write those methods in one struct and then copy them to the other. Now if you find bugs in some of them you have to remember to fix it in two places, or if you experiment with improving them you then need to remember to apply the same improvements in other places, etc. Instead you can write these methods once in a separate struct and then just mix them in, or in other words make them a part of other structs.\nCurrently the Zig standard library is not using this approach so there is another solution for this but it has its own problems and I plan to analyze and propose alternatives to it in a future post.\nNote that the example I gave only mixes in additional behavior while, in general, mixins might also allow mixing in state, or in other words additional fields. In Zig you can’t mix in additional fields only functions and consts, but mixin code does have access to its modules global variables. The cases where you actually need to mix in state are very rare and I couldn’t come up with a single non contrived example to show here.\nHow are mixins done in Zig Currently Zig has a usingnamespace keyword that will make all the consts and methods of the given struct available in the current namespace, which in Zig is always another struct. Note that there is a proposal to actually change it to mixin or something like it so it might be different when you read this.\nLet’s see how would the example I gave above actually be implemented. First we will define the methods we want to mix in.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fn ReaderMethods(comptime Self: type) type { return struct{ pub fn readInt(self: *Self) !i8 { var intBuffer: [4]u8 = undefined; _ = try self.read(intBuffer[0..]); return std.mem.bytesToValue(i32, intBuffer[0..]); } pub fn readStruct(comptime StructType: type) { // Only extern and packed structs have defined in-memory layout. comptime assert(@typeInfo(T).Struct.layout != .Auto); var res: [1]T = undefined; try self.read(mem.sliceAsBytes(res[0..])); return res[0]; } } } So the first thing is that struct that you want to mix into other types has to be generic if you want it to provide additional methods to target struct. The reason is that the first argument to struct methods must be of the type of that struct and the only way for mixin code to know the type of target struct is to pass it as a parameter of the generic function that generates it. The word comptime before the parameter in Zig means that the value passed for that parameter must be known at compile time. You can read more about it here and here.\nYou might also notice that the mixin function accepts any kind of type as its argument but later code then expects that that type has a read() method on a highlighted fifth line. If a user passes something that doesn’t have a read method with that specific signature they will get a compile error. Something like this:\nerror: no member named 'read' in struct 'TargetStruct' The line on which the error is reported is the one in above mixin struct. In some situations this might be completely fine but in others it might be better to provide a better error like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 fn ReaderMethods(comptime Self: type, comptime ReadError: type) type { if (!@hasDecl(Self, \"read\")) { @compileError(\"Expected a read(*\" ++ @typeName(Self) ++ \", []const u8) \" ++ @typeName(ReadError) ++ \"!usize method in \" ++ @typeName(Self)); } if (@TypeOf(Self.read) != fn(*Self, []const u8) ReadError!usize) { @compileError(\"Expected a read(*\" ++ @typeName(Self) ++ \", []const u8) \" ++ @typeName(ReadError) ++ \"!usize method in \" ++ @typeName(Self) ++ \" but got \" ++ @typeName(@TypeOf(Self.read))); } return struct{ … }; } This will report the error on one of the @compileError lines but it will also show the line where it was mixed in.\nIn order to mix the above behavior into a File struct you would just do this:\n1 2 3 4 5 6 7 8 9 10 11 pub const File = struct { ... const Self = @This(); pub fn read(self: *Self, buffer: []const u8) ReadError!usize { ... } pub usingnamespace ReaderMethods(Self, ReadError); } That one line does the job. You would add the same to TcpSocket and get the job done.\nExample with color types Different image and graphic libraries support different formats of representing pixels. Most common way is to store it as three values for red, green and blue channels. Still there could be a different number of bits for each channel, there could additionally be an alpha channel and the order of channels in memory could be different. How can we easily represent all those variations with structs and also provide them all with some common conversion methods like fromU32Rgba() and toU32Rgba()?\nUsing the mixins we can easily provide these methods:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 fn RgbColor(comptime T: type) type { return packed struct { r: T, g: T, b: T, pub usingnamespace RgbMethods(@This()); }; } fn RgbaColor(comptime T: type) type { return packed struct { r: T, g: T, b: T, a: T = math.maxInt(T), pub usingnamespace RgbMethods(@This()); }; } fn BgrColor(comptime T: type) type { return packed struct { b: T, g: T, r: T, pub usingnamespace RgbMethods(@This()); }; } fn BgraColor(comptime T: type) type { return packed struct { b: T, g: T, r: T, a: T = math.maxInt(T), pub usingnamespace RgbMethods(@This()); }; } fn RgbMethods(comptime Self: type) type { return struct { const RedT = std.meta.fieldInfo(Self, .r).field_type; const GreenT = std.meta.fieldInfo(Self, .g).field_type; const BlueT = std.meta.fieldInfo(Self, .b).field_type; const AlphaT = RedT; // We assume Alpha type is same as Red type pub fn fromU32Rgba(value: u32) Self { var res = Self{ .r = scaleToIntColor(RedT, @truncate(u8, value \u003e\u003e 24)), .g = scaleToIntColor(GreenT, @truncate(u8, value \u003e\u003e 16)), .b = scaleToIntColor(BlueT, @truncate(u8, value \u003e\u003e 8)), }; if (@hasField(Self, \"a\")) res.a = scaleToIntColor(AlphaT, @truncate(u8, value)); return res; } pub fn toU32Rgba(self: Self) u32 { return @as(u32, scaleToIntColor(u8, self.r)) \u003c\u003c 24 | @as(u32, scaleToIntColor(u8, self.g)) \u003c\u003c 16 | @as(u32, scaleToIntColor(u8, self.b)) \u003c\u003c 8 | if (@hasField(Self, \"a\")) scaleToIntColor(u8, self.a) else 0xff; } }; } In this example you can also see how we used if (@hasField(Self, \"a\")) in the mixin struct in order to support alpha channel only if it exists in the target struct.\nThe scaleToIntColor() function makes sure that the final value is scaled to the target number of bits even if the original value uses a different number of bits. For example, if u5 is used minimum value will be 0 and maximum will be 31 but if we need to convert that to u8, 0 needs to stay 0 but 32 needs to become 255, while 16 will need to become 132, for example. This is how it looks like:\n1 2 3 4 5 6 7 8 9 10 11 12 13 pub inline fn scaleToIntColor(comptime T: type, value: anytype) T { const ValueT = @TypeOf(value); const cur_value_bits = @bitSizeOf(ValueT); const new_value_bits = @bitSizeOf(T); if (cur_value_bits \u003e new_value_bits) { return @truncate(T, value \u003e\u003e (cur_value_bits - new_value_bits)); } else if (cur_value_bits \u003c new_value_bits) { const cur_value_max = math.maxInt(ValueT); const new_value_max = math.maxInt(T); return @truncate(T, (@as(u32, value) * new_value_max + cur_value_max / 2) / cur_value_max); } else return @as(T, value); } So if we need to convert from bigger to smaller type we just shift the bits we don’t need out using right shift and then truncate to the smaller type. But if we need to convert from smaller to bigger type we do some math in order to properly scale the value from a smaller range to a bigger range.\nConditional mixin Since Zig supports expressions that return types there is a way to use mixins to only define methods in certain cases. For example lets say that we want RgbMethods above to also provide toPremultipliedAlpha() method but only if target type has an alpha channel. We can do it like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fn RgbMethods(comptime Self: type) type { return struct { ... pub usingnamespace if (@hasField(Self, \"a\")) struct { pub fn toPremultipliedAlpha(self: Self) Self { const max = math.maxInt(T); return Self{ .r = @truncate(RedT, (@as(u32, self.r) * self.a + max / 2) / max), .g = @truncate(GreenT, (@as(u32, self.g) * self.a + max / 2) / max), .b = @truncate(BlueT, (@as(u32, self.b) * self.a + max / 2) / max), .a = self.a, }; } } else struct {} }; } Here we used inline mixin within RgbMethods mixin that we only mix in if target type has a field :).\nConclusion This programming pattern is very powerful and can solve some tricky problems in a very elegant way.\nOne downside to these kind of solutions is that they generate a lot of code when compiled, because now the compiler is copying that code for you. In some cases the optimizer might be able to consolidate it if you are making an optimized build but there is no way to know upfront if that will work. On the other hand that amount of compiled code will most likely be insignificant in any kind of useful program so there are very limited cases where that size might be a factor.\nAlso note that Zig compiler will only generate code for definitions that are actually used by the program and not for every possible definition which also reduces this problem a lot.\nWhat do you think about this pattern? Do you see any other downsides to using it? If you interested in discussing it join us on Ziggit forum.\n","description":"","tags":["zig","programming","mixins"],"title":"Mixins in Zig","uri":"/blog/mixins-in-zig/"},{"content":"Many of the top used programming languages today use garbage collection and with them we are always taught how manual memory management is hard. I get the feeling that many new programmers don’t even try to understand it today.\nI want to show here how manual memory management can be not only very easy but also very fun.\nLesson 1: Let Operating System Do It There is a big class of programs that work as command line utilities. They run, do their job and exit. Most of them don’t need a lot of memory during their entire operation. In programs like this you can act as if you have a garbage collector even when you don’t because when your program exits the operating system will clean up all the memory it used.\nSo the best strategy in these kinds of programs is to just allocate memory wherever you need and not think about it.\nLesson 2: What Is Memory Anyway As soon as you go to a bit more complicated programs you need a better understanding of what memory is and how it can be used in your programs.\nFirst thing you need to learn is the difference between stack and heap memory.\nStack memory When you compile and link your code you produce an executable and in it will also be stored how much stack memory it needs. There are ways to specify that manually while linking but linkers have a default value for it. It is usually 8MB but on Windows it might be just 1MB.\nWhen your program starts, the OS reserves that much space and sets up a special register to point to the start of that memory. Now whenever you define a local variable in your program it gets stored on stack. Also when you call some function the return address and all or some of the parameters are also stored there. For example if in some function you define a local variable as an array of 100 integers and if one integer takes 4 bytes you just allocated 400 bytes from the stack memory. So now how is that memory freed? Well since every local variable and function parameter can’t be used when you return from that function all the memory for that function is automatically freed.\nSo whenever the program enters a new function and new local variables are declared we say the stack grows and whenever we return from a function we say the stack shrinks and that register that points to the first free location is incremented or decremented.\nThat makes this method of allocation and deallocation the simplest one.\nIf you spend all the stack memory that was reserved for your program and you try to make another function call the program will fail with Stack Overflow error.\nImportant to note is that compilers usually compile the code in such a way that as soon as a function is entered the space for all local variables is immediately reserved. Even if some variable is only used in some conditional block, space for it will be reserved at the start of the function. That is why Stack Overflow errors happen only on entering new functions.\nHeap memory This is usually additional memory that you can request from the OS and this is the memory that you actually need to manage and properly release when no longer needed. It is used whenever you need to store and keep something, even when you return from some function where it is created or if it is too big to fit on the stack.\nWhen you get this memory what you actually have is a pointer to the first address within it and how much after that address is available. Some languages such as Zig represent those two things as one thing called a slice. You can read more about Zig slices here.\nAnyway it is up to you now how you want to interpret that memory. Is it one integer or an array of integers, or maybe a float, a character or some structure. In zig you can use one of these\n1 2 std.mem.bytesAsValue(comptime T: type, bytes: anytype) std.mem.bytesToValue(comptime T: type, bytes: anytype) to interpret the given array of bytes as a given T type.\nIf you are coming from object oriented and garbage collected language you might know that whenever you call new SomeClass() the memory for that object is allocated and that object is created but you can not imagine how you could control where and how it takes that memory. What the language does for you is actually allocate memory for the data of that class, casts the pointer it gets to the type of that class, then calls your constructor function and returns you that casted pointer. As you can see you can easily do so yourself with just a struct and some function that initializes the fields of that struct like a constructor would. Of course, unlike GC langauges you might also need to manually release that memory when you no longer need it.\nNow calling the OS whenever you need a few bytes of memory would ruin your performance because system calls are expensive. That is why languages usually come with some sort of Allocators.\nLesson 3: Allocators Allocators reserve more memory from the system than you currently need so they actually manage a pool of memory that you can then efficiently borrow from whenever you need it. C only comes with malloc which is a general purpose allocator but zig comes with more options.\nGeneral purpose allocator needs to try and be efficient no matter how you use it. Do you allocate a lot of small objects or big ones or a mix of both, do you free often or rare, in small chunks or in bulk. They also have to handle memory fragmentation.\nIf you imagine memory as a row of bytes where allocation reserves some of those bytes and freeing it makes those bytes available for future use you can also imagine how after some usage there might be a lot of little boxes that are available for use in between boxes that are still in use. Now if you want to allocate something bigger there might be enough total free bytes but none of the boxes might be big enough individually. That means your memory is fragmented and a lot of it becomes unusable.\nBecause of all of that general purpose allocators are the most complicated and often less efficient than specialized allocators tailored for each use.\nOne example is ArenaAllocator. It doesn’t support freeing individual allocations at all. The idea is that you use it within a part of your program which does some processing and needs to do a number of allocations none of which will be needed once the processing is complete. That way that part of the program can just allocate things and not think about freeing them and once the processing is complete you can just call ‘free everything’ on the ArenaAllocator itself. It is initialized with another allocator from which the actual allocating and freeing is done.\nYet another is FixedBufferAllocator. It is initialized with a limited array of bytes that you want to be served as memory from it. If the process then tries to allocate more memory from it than that array contains it will get an error. It is useful to make sure parts of the program don’t accidentally allocate more than they should or that they don’t leak memory. It is also useful because you can initialize it with a local array that is on the stack and pass that as an allocator to some library. You can only do this if the library has documented how much maximum memory it will need to do its job and if that amount can fit on the stack. This way the actual allocation it does through that allocator will be as cheap as possible and plus after its job is done all the memory is guaranteed to be freed.\nYou can also use StackFallbackAllocator with a certain size, which will under the hood use a FixedBufferAllocator on stack while the allocations fit in the given size and then start using a provided fallback allocator for the rest of allocations.\nSome others are PageAllocator which always allocates whole pages from the OS, which are usually 4KiB in size and LoggingAllocator that can log each allocation that happens through it.\nNow with just these you now have a lot of tools in your arsenal you can play with.\nExamples Compiler Compilers usually work in multiple passes. Each pass goes through data from the previous pass and generates new or modifies existing data. Input for the first pass is of course a code file which can also be thought of as a long string that needs to be parsed.\nAs each pass works it will need to allocate some temporary memory for its operation. For that purpose it is best to allocate one block big enough to fit estimated temporary allocations of each pass, maybe through PageAllocator and then make one FixedBufferAllocator over that memory that you will call the reset() on after each pass. That will simply make the whole buffer it uses ready to be used from start for the next pass thus reusing that initial allocation for each pass. It will also limit the temporary memory each pass can take so you can detect memory leaks earlier.\nFor the things that one pass generates for the next to use it might be best to use ArenaAllocator. That way if there is a pass in the pipeline that generates completely new data from the previous ones you can just call deinit() on that allocator to free all the memory allocated from previous passes at once.\nEither way the memory that you need all the way until the end of the compiling process probably doesn’t need to be manually freed at all since the compiler process will shutdown when it is finished and the OS will clean up all its memory anyway.\nImage loader If you are writing a lib that needs to parse some file formats like png or jpg and return parsed pixels it is best to allow the users to pass in the allocator that should be used. The catch is that besides allocating space for resulting data the lib might need to allocate some temporary memory for processing. It could just use the same allocator and in that case the best practice would be to first allocate the space for the result and then start allocating and freeing the temporary data. That way you minimize the possibility for fragmenting memory.\nIf you can guarantee the temporary space needed no matter the image size then you can internally make a FixedBufferAllocator that will also quickly catch if you by mistake miss that target. If the amount is also small you can just define a local array on the stack to serve as a backing buffer for that allocator. Otherwise you would probably allocate the buffer from the given allocator.\nThird option could be that you allow the user to pass in an additional allocator for temporary allocations. It is best if you at least make it optional if you don’t expect users will need that level of customization often. You can still internally combine the methods above with that allocator.\nConclusion Hopefully with just these two examples you can see that memory management can often be made very simple. Also solving the issue of memory can be an interesting pursuit of simplicity and flexibility.\nAlso note that although the principles described here should be applicable to any system programming language each of them will have its own quirks, especially C and C++. The zig is the first language I know that was designed not to have a globally accessible allocator, for example, which forces you to be deliberate about your allocations and this post was written with it in mind.\nIf you want to learn more and practice, I strongly suggest you try the Zig language. Try to solve some of the issues you worked on in the past using this language and its conventions and see how much fun you find along the way ;).\n","description":"","tags":["zig","programming","memory"],"title":"Basics of Allocating and Using Memory","uri":"/blog/basics-of-allocating-and-using-memory/"},{"content":"","description":"","tags":null,"title":"csharp","uri":"/tags/csharp/"},{"content":"There are often situations where logging can affect performance. It is probably rare in the server world but it comes quite often when we try to log stuff in our Unity game. There its effect can be quite visible.\nThat is why, so far, we disabled all logger calls in our production builds by using a [Conditional(\"USE_LOGGING\")] attribute on logger methods and not defining the USE_LOGGER symbol in the build. You can read about that attribute here.\nBut our project grew and grew and at one point became complex enough that we had to reconsider. We needed an option to leave the logging lines in the code but have them disabled by default unless the backend server tells the game to enable some log levels for some tags. So the logging line would look something like this:\n1 2 3 4 5 // logger instance is created somewhere with some // specific tag that it will add for each log line // The call then looks like this: logger.Info($\"User {userId} from {cityName} logged in on {logInTime}.\"); The code inside that method would check if Info level is enabled for that logger’s tag and wouldn’t log the message if it isn’t. Here we were still concerned that the string interpolations would create enough garbage for the Garbage Collector that its cleanups would again slow down our game. Now, if you did any C# programming you will now be thinking: “Why are you using string interpolations? That is not how you should use the logger API. You should pass in a format string in arguments separately.”. You would be right, but it also doesn’t really stop you from using it that way. Also there is already a lot of code in our 7 years old project that uses code like this. Even if we did it the “correct” way it would still need to execute code that generates the values for arguments and to possibly box those arguments only to then conclude it doesn’t need any of that inside the method because logs are disabled for that tag and level.\nThe best solution we found online is a great Zero Allocation Logger. It also avoids boxing of parameters by having many overloads for logging methods with different number of generic parameters. It would still require that we refactor our huge code base never to use string interpolation and the api still expects string as a first parameter so it can’t force the developer not to use string interpolation.\nIn the end we did some measurements and concluded that impact isn’t as bad as we thought so we will try to just roll with what we have. But then I had a…\nBrilliant Idea So, from performance standpoint it would be ideal if our developers wouldn’t hate to always type:\n1 2 3 if (logger.IsEnabledFor(LogLevel.Info)) { logger.Info($\"User {userId} from {cityName} logged in on {logInTime}.\"); } But of course they do. Not just to type but also to read. There comes my brilliant idea. What if Info is a property instead of a method and that property returns an optional struct that has the Log() method. Then the usage would look like this:\n1 logger.Info?.Log($\"User {userId} is starting a match {matchId} with {injuredNum} injured players.\"); This is much less painful to type and read. If the logging is disabled the property will return null and the part after ?. will not be executed at all. On the other hand if it is enabled it will return the struct which doesn’t allocate any memory on the heap. If you accidentally try to call the .Log() method without ?. you will get a compile error.\nIf we wanted to convert all our log calls to this we could just execute Regex search and replace a few times.\nWe haven’t yet tried to put this idea into practice but it felt too cool not to share immediately.\n","description":"","tags":["programming","csharp"],"title":"Optimal Logging API for C#","uri":"/blog/optimal-logging-api-for-csharp/"},{"content":"","description":"","tags":null,"title":"png","uri":"/tags/png/"},{"content":"Although there is already a solid zigimg image loading library it didn’t quite tick all the checkboxes for me. It doesn’t provide the flexibility that I am aiming for and it is using far more allocations than is necessary. Also since I already wrote a png reader in DLang it felt like a good project for learning zig to try to reimplement it and try to improve on my original design.\nYou can find the solution I came up with here. In order to understand my design we first need to know a bit about the png format. The Png file is a sequence of chunks of different types. Each chunk has a 4 byte id, represented as 4 ascii letters. Some examples are:\nIHDR for a header chunk that contains things like width, height and pixel format PLTE for a palette chunk in case pixels are stored as indices into that palette tRNS for a chunk that says what color should be considered as transparent The specification says that if the first letter of the id is upper case it is a critical chunk that the reader must know how to parse. Otherwise the chunk is optional and the image can be displayed without parsing it but it might not be displayed completely as intended.\nSo my idea was to create a reader that can parse critical chunks and allow users to register parsers for any number of optional chunks. It would also come with some chunk parsers implemented but in such a way that they are not even compiled in if they are not used. I didn’t quite manage to accomplish that in the first version I wrote in DLang but I am pretty happy with what I managed to write so far in Zig.\nThis is the API I came up with so far:\n1 2 3 4 const file = try cwd.openFile(\"image.png\", .{ .mode = .read_only }); var reader = pngreader.fromFile(file); var header = try reader.loadHeader(); var pixelData = reader.loadWithHeader(\u0026header, allocator, options); In case you already have the whole file loaded into memory you can also use pngreader.fromMemory(u8buffer);. Also if you don’t want to handle the header separately but just load the image you can just call reader.load(allocator, options).\nThe key to the design is, of course, the options argument. Its type is defined like this:\n1 2 3 4 pub const ReaderOptions = struct { temp_allocator: Allocator, processors: []ReaderProcessor = \u0026[_]ReaderProcessor{}, }; It provides a way for you to specify a separate allocator that will be used for temporary allocations during loading and it is bounded to 800KiB at the moment but I hope to reduce it in the future. The other thing is a slice of processors for different chunk types. Each ReaderProcessor has an id which says what chunk type it is dedicated to and it provides processChunk and optional processPalette and processDataRow functions. It is actually an interface to specific implementation just like Allocator struct represents a common interface for different implementations of allocators. You can register a processor for critical or optional chunk but in case of optional chunks it will be a responsibility of its processChunk function to read in or seek over the bytes of its chunk from underlining stream reader while for critical chunks it must not do that but just use the passed in data. The other two methods allow each processor to affect the palette or pixel data as they are loaded using the info they parsed.\nCurrently the reader comes with two processors implemented: TrnsProcessor and PlteProcessor.\nTrnsProcessor will parse the tRNS chunk if it exists and extract what colors should be considered transparent. It will then add an alpha channel to the image format and place that info there. So if the image is in Grayscale format it will become GrayscaleAlpha and if it is in RGB format it will become RGBA and in the alpha channel 0 will be written for a color that needs to be considered transparent and 255 for others.\nPlteProcessor, if the image is in Indexed format will change that to RGB format and will convert pixel data so that instead of palette indices it contains the actual RGB values from the palette directly. Note that if you also use TrnsProcessor and the tRNS chunk also exists the final format will be RGBA since it will also add an alpha channel.\nSo if you just pass a default for the options argument:\n1 var pixelData = reader.loadWithHeader(\u0026header, allocator, .{}); no processors will be used or compiled in and a static buffer on stack will be used for temporary allocations. If you want to use default options that include the above two processors you can just do this:\n1 2 var def_options = DefOptions{}; var pixelData = reader.loadWithHeader(\u0026header, allocator, def_options.get()); It will also use a stack buffer for temporary allocations but it will use both of the above processors.\nIn case you implement additional processors, for example for sRGB and cHRM chunks you could call it with them like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 var trns = TrnsProcessor{}; var plte = PlteProcessor{}; var srgb = SrgbProcessor{}; var chrm = ChrmProcessor{}; var processors = [_]ReaderProcessor{ trns.processor(), plte.processor(), srgb.processor(), chrm.processor(), }; var tmp_buffer: [800 * 1024]u8 = undefined; var fb_allocator = std.heap.FixedBufferAllocator.init(tmp_buffer[0..]); var options = ReaderOptions.initWithProcessors(fb_allocator.allocator(), processors[0..]); Also if you want to use these as default throughout your project you can just define a struct called DefPngOptions in your root file in the same way DefOptions struct is defined in the reader.\nThe API for non default options is a bit verbose because you need to provide the place for all the pieces. In the above case they are all on stack. On the other hand I made default usage as simple as I could and I also provided more flexibility than any other png loader I found without sacrificing its memory efficiency or performance.\nI hope to cover a bit about how I handle the memory in a separate post. Until then happy Zigging!\n","description":"","tags":["zig","png","programming"],"title":"Png Reader in Zig","uri":"/blog/png-reader-in-zig/"},{"content":"","description":"","tags":null,"title":"engine","uri":"/tags/engine/"},{"content":"","description":"","tags":null,"title":"game","uri":"/tags/game/"},{"content":"I am doing programming for 24 years now and I don’t see myself getting bored with it. There is always one more thing to learn or to solve and I really want to know everything .\nThe goal I am most interested in is making my own game engine. But I don’t want to take the SDL library, some image and 3D data loading library and just write rendering logic. I want to learn how it all works.\nI want to know how windowing is done on different platforms, how inputs are processed, how sound is produced, how images or sounds or 3D models are parsed and loaded. I want to know every little thing that comes on the way.\nI don’t care that I will never get done. I don’t care if in 10 years I am still scratching the surface. As long as I am learning something new I am happy.\nObstacles I do have to confess it is easy to get sidetracked. I want to write the png loader, but for that I need a decompression library which needs an Adler hashing algorithm. I would check if there are good implementations of those in the language I am working on but if for any reason I am not happy about that implementation or I find someone wrote a better one in another language I want to port that or write a new one that is to my liking.\nSometimes I realize I am not happy with the language I chose so I would investigate others until I find a new pet. Or if I don’t find anything at the moment I might even try to write a compiler for my own language. At some point I also realize the path I took doesn’t hold my interest any more so I would go back and just choose some other path. Something interesting to learn is everywhere.\nIt also surprised me how often the things I learned turned out useful in my job even though I chose my hobbies to be different. On the other hand, I specifically chose not to go into making my own operating system. It would be too much removed from my daily work and I do have my limits.\nBesides all of this I always have motivation to play some games or watch movies or read books but about that some other time.\n","description":"","tags":["personal","game","engine"],"title":"How do I stay motivated","uri":"/blog/how-do-i-stay-motivated/"},{"content":"","description":"","tags":null,"title":"personal","uri":"/tags/personal/"},{"content":"","description":"","tags":null,"title":"Blog","uri":"/blog/"},{"content":"\nWhat is the closest thing in this world to magic?\nTo me it will always be programming. You type in some incantations and stuff happens .\nHere I want to document and share my explorations into this magic world. My most recent trip went into Zig land so most of the articles will talk about that.\nBut who am I? I got my first PC in 1997, when I was 13 years old and I got my hands on my first programming language somewhere in 1998. It was QBasic and I created some of the first games and programs in it. I wrote Hangman, Mastermind, Breakout and even did something like a Paint program.\nI shortly switched to Pascal and then jumped to Delphi (or Object Pascal). There I learned about the SDL library and OpenGL and made a clone of Nintendo’s Battle city game and 3D Rubik’s Cube solver.\nWhile doing that I realized how hard it is to create UI for a game, especially compared to Delphi which I consider is still unmatched in ease of use for creating desktop UIs. So, as I was finishing high school, I wrote a UI library called SDLControls for Object Pascal.\nDuring high school I also learned a bit about assembler and how CPUs work on a lower level. It was fascinating at the time.\nAs college started I lost my free time and didn’t do much outside of school projects which included Pascal, C, Java, C# and PHP. Straight from college I started working on Java business software in 2007. During the next four years I would move from the first company, to the second and third until in 2011 I got a job at a startup gaming company. One of the first in my country.\nThe company was a success and 11 years later I am still working at Nordeus doing my dream job. Surprisingly, for my younger self it turned out not to be making games itself, but rather making tools for making games .\nI started on some web applications with PHP and Javascript and then moved to Unity and C#. But that fascination about the inner workings of the PC from younger days is still burning in me so I still find some side projects to play with in my free time.\nCasey Muratory with his Handmade Hero series series and Jonathan Blow with his talks about a custom compiler were a great inspiration. Thanks to them I refreshed my C knowledge and wrote a tiny compiler, Summus, as a sort of introduction to writing one using LLVM as a backend.\nI then learned what I could about other new languages and among Rust, Go, Nim and DLang I chose the latter as the most intuitive and powerful language. Coming from Unity and C# DLang seemed like a perfect language for a Game Engine. It supports garbage collection but also manual memory management so it seemed like I could use it to write both low level systems and later use it as gameplay logic language as well. No need for separate scripting language.\nUnfortunately I got disappointed with some drawbacks of the language and the fact that its leadership didn’t seem very interested to work on those things. At the time Odin and Zig also came under my radar and so I decided to play with Zig and document my journey here.\nAnd so here we are!\n","description":"","tags":null,"title":"About Me","uri":"/more/about-me/"},{"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/"}]