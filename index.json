[{"content":"Welcome to Dr Iggy’s coding adventures ","description":"","tags":null,"title":"Dr Iggy's Coding Adventures","uri":"/"},{"content":"","description":"","tags":null,"title":"mixins","uri":"/tags/mixins/"},{"content":"What are mixins? Mixins are a way to mix in some common functionality into multiple structs. For example if you have a File and TcpSocket and they have their own different implementations of read(buffer: []u8) method and you want to add convenience methods like readInt(), readStruct() and similar that just call the read() method and format the result, you would usually have to write those methods in one struct and then copy them to the other. Now if you find bugs in some of them you have to remember to fix it in two places, or if you experiment with improving them you then need to remember to apply the same improvements in other places, etc. Instead you can write these methods once in a separate struct and then just mix them in, or in other words make them a part of other structs.\nCurrently the Zig standard library is not using this approach so there is another solution for this but it has its own problems and I plan to analyze and propose alternatives to it in a future post.\nNote that the example I gave only mixes in additional behavior while, in general, mixins might also allow mixing in state, or in other words additional fields. In Zig you can’t mix in additional fields only functions and consts, but mixin code does have access to its modules global variables. The cases where you actually need to mix in state are very rare and I couldn’t come up with a single non contrived example to show here.\nHow are mixins done in Zig Currently Zig has a usingnamespace keyword that will make all the consts and methods of the given struct available in the current namespace, which in Zig is always another struct. Note that there is a proposal to actually change it to mixin or something like it so it might be different when you read this.\nLet’s see how would the example I gave above actually be implemented. First we will define the methods we want to mix in.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fn ReaderMethods(comptime Self: type) type { return struct{ pub fn readInt(self: *Self) !i8 { var intBuffer: [4]u8 = undefined; _ = try self.read(intBuffer[0..]); return std.mem.bytesToValue(i32, intBuffer[0..]); } pub fn readStruct(comptime StructType: type) { // Only extern and packed structs have defined in-memory layout. comptime assert(@typeInfo(T).Struct.layout != .Auto); var res: [1]T = undefined; try self.read(mem.sliceAsBytes(res[0..])); return res[0]; } } } So the first thing is that struct that you want to mix into other types has to be generic if you want it to provide additional methods to target struct. The reason is that the first argument to struct methods must be of the type of that struct and the only way for mixin code to know the type of target struct is to pass it as a parameter of the generic function that generates it. The word comptime before the parameter in Zig means that the value passed for that parameter must be known at compile time. You can read more about it here and here.\nYou might also notice that the mixin function accepts any kind of type as its argument but later code then expects that that type has a read() method on a highlighted fifth line. If a user passes something that doesn’t have a read method with that specific signature they will get a compile error. Something like this:\nerror: no member named 'read' in struct 'TargetStruct' The line on which the error is reported is the one in above mixin struct. In some situations this might be completely fine but in others it might be better to provide a better error like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 fn ReaderMethods(comptime Self: type, comptime ReadError: type) type { if (!@hasDecl(Self, \"read\")) { @compileError(\"Expected a read(*\" ++ @typeName(Self) ++ \", []const u8) \" ++ @typeName(ReadError) ++ \"!usize method in \" ++ @typeName(Self)); } if (@TypeOf(Self.read) != fn(*Self, []const u8) ReadError!usize) { @compileError(\"Expected a read(*\" ++ @typeName(Self) ++ \", []const u8) \" ++ @typeName(ReadError) ++ \"!usize method in \" ++ @typeName(Self) ++ \" but got \" ++ @typeName(@TypeOf(Self.read))); } return struct{ … }; } This will report the error on one of the @compileError lines but it will also show the line where it was mixed in.\nIn order to mix the above behavior into a File struct you would just do this:\n1 2 3 4 5 6 7 8 9 10 11 pub const File = struct { ... const Self = @This(); pub fn read(self: *Self, buffer: []const u8) ReadError!usize { ... } pub usingnamespace ReaderMethods(Self, ReadError); } That one line does the job. You would add the same to TcpSocket and get the job done.\nExample with color types Different image and graphic libraries support different formats of representing pixels. Most common way is to store it as three values for red, green and blue channels. Still there could be a different number of bits for each channel, there could additionally be an alpha channel and the order of channels in memory could be different. How can we easily represent all those variations with structs and also provide them all with some common conversion methods like fromU32Rgba() and toU32Rgba()?\nUsing the mixins we can easily provide these methods:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 fn RgbColor(comptime T: type) type { return packed struct { r: T, g: T, b: T, pub usingnamespace RgbMethods(@This()); }; } fn RgbaColor(comptime T: type) type { return packed struct { r: T, g: T, b: T, a: T = math.maxInt(T), pub usingnamespace RgbMethods(@This()); }; } fn BgrColor(comptime T: type) type { return packed struct { b: T, g: T, r: T, pub usingnamespace RgbMethods(@This()); }; } fn BgraColor(comptime T: type) type { return packed struct { b: T, g: T, r: T, a: T = math.maxInt(T), pub usingnamespace RgbMethods(@This()); }; } fn RgbMethods(comptime Self: type) type { return struct { const RedT = std.meta.fieldInfo(Self, .r).field_type; const GreenT = std.meta.fieldInfo(Self, .g).field_type; const BlueT = std.meta.fieldInfo(Self, .b).field_type; const AlphaT = RedT; // We assume Alpha type is same as Red type pub fn fromU32Rgba(value: u32) Self { var res = Self{ .r = scaleToIntColor(RedT, @truncate(u8, value \u003e\u003e 24)), .g = scaleToIntColor(GreenT, @truncate(u8, value \u003e\u003e 16)), .b = scaleToIntColor(BlueT, @truncate(u8, value \u003e\u003e 8)), }; if (@hasField(Self, \"a\")) res.a = scaleToIntColor(AlphaT, @truncate(u8, value)); return res; } pub fn toU32Rgba(self: Self) u32 { return @as(u32, scaleToIntColor(u8, self.r)) \u003c\u003c 24 | @as(u32, scaleToIntColor(u8, self.g)) \u003c\u003c 16 | @as(u32, scaleToIntColor(u8, self.b)) \u003c\u003c 8 | if (@hasField(Self, \"a\")) scaleToIntColor(u8, self.a) else 0xff; } }; } In this example you can also see how we used if (@hasField(Self, \"a\")) in the mixin struct in order to support alpha channel only if it exists in the target struct.\nThe scaleToIntColor() function makes sure that the final value is scaled to the target number of bits even if the original value uses a different number of bits. For example, if u5 is used minimum value will be 0 and maximum will be 31 but if we need to convert that to u8, 0 needs to stay 0 but 32 needs to become 255, while 16 will need to become 132, for example. This is how it looks like:\n1 2 3 4 5 6 7 8 9 10 11 12 13 pub inline fn scaleToIntColor(comptime T: type, value: anytype) T { const ValueT = @TypeOf(value); const cur_value_bits = @bitSizeOf(ValueT); const new_value_bits = @bitSizeOf(T); if (cur_value_bits \u003e new_value_bits) { return @truncate(T, value \u003e\u003e (cur_value_bits - new_value_bits)); } else if (cur_value_bits \u003c new_value_bits) { const cur_value_max = math.maxInt(ValueT); const new_value_max = math.maxInt(T); return @truncate(T, (@as(u32, value) * new_value_max + cur_value_max / 2) / cur_value_max); } else return @as(T, value); } So if we need to convert from bigger to smaller type we just shift the bits we don’t need out using right shift and then truncate to the smaller type. But if we need to convert from smaller to bigger type we do some math in order to properly scale the value from a smaller range to a bigger range.\nConditional mixin Since Zig supports expressions that return types there is a way to use mixins to only define methods in certain cases. For example lets say that we want RgbMethods above to also provide toPremultipliedAlpha() method but only if target type has an alpha channel. We can do it like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fn RgbMethods(comptime Self: type) type { return struct { ... pub usingnamespace if (@hasField(Self, \"a\")) struct { pub fn toPremultipliedAlpha(self: Self) Self { const max = math.maxInt(T); return Self{ .r = @truncate(RedT, (@as(u32, self.r) * self.a + max / 2) / max), .g = @truncate(GreenT, (@as(u32, self.g) * self.a + max / 2) / max), .b = @truncate(BlueT, (@as(u32, self.b) * self.a + max / 2) / max), .a = self.a, }; } } else struct {} }; } Here we used inline mixin within RgbMethods mixin that we only mix in if target type has a field :).\nConclusion This programming pattern is very powerful and can solve some tricky problems in a very elegant way.\nOne downside to these kind of solutions is that they generate a lot of code when compiled, because now the compiler is copying that code for you. In some cases the optimizer might be able to consolidate it if you are making an optimized build but there is no way to know upfront if that will work. On the other hand that amount of compiled code will most likely be insignificant in any kind of useful program so there are very limited cases where that size might be a factor.\nWhat do you think about this pattern? Do you see any other downsides to using it? If you interested in discussing it join us on Ziggit forum.\n","description":"","tags":["zig","programming","mixins"],"title":"Mixins in Zig","uri":"/blog/mixins-in-zig/"},{"content":"","description":"","tags":null,"title":"programming","uri":"/tags/programming/"},{"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/"},{"content":"","description":"","tags":null,"title":"zig","uri":"/tags/zig/"},{"content":"Many of the top used programming languages today use garbage collection and with them we are always taught how manual memory management is hard. I get the feeling that many new programmers don’t even try to understand it today.\nI want to show here how manual memory management can be not only very easy but also very fun.\nLesson 1: Let Operating System Do It There is a big class of programs that work as command line utilities. They run, do their job and exit. Most of them don’t need a lot of memory during their entire operation. In programs like this you can act as if you have a garbage collector even when you don’t because when your program exits the operating system will clean up all the memory it used.\nSo the best strategy in these kinds of programs is to just allocate memory wherever you need and not think about it.\nLesson 2: What Is Memory Anyway As soon as you go to a bit more complicated programs you need a better understanding of what memory is and how it can be used in your programs.\nFirst thing you need to learn is the difference between stack and heap memory.\nStack memory When you compile and link your code you produce an executable and in it will also be stored how much stack memory it needs. There are ways to specify that manually while linking but linkers have a default value for it. It is usually 8MB but on Windows it might be just 1MB.\nWhen your program starts, the OS reserves that much space and sets up a special register to point to the start of that memory. Now whenever you define a local variable in your program it gets stored on stack. Also when you call some function the return address and all or some of the parameters are also stored there. For example if in some function you define a local variable as an array of 100 integers and if one integer takes 4 bytes you just allocated 400 bytes from the stack memory. So now how is that memory freed? Well since every local variable and function parameter can’t be used when you return from that function all the memory for that function is automatically freed.\nSo whenever the program enters a new function and new local variables are declared we say the stack grows and whenever we return from a function we say the stack shrinks and that register that points to the first free location is incremented or decremented.\nThat makes this method of allocation and deallocation the simplest one.\nIf you spend all the stack memory that was reserved for your program and you try to make another function call the program will fail with Stack Overflow error.\nImportant to note is that compilers usually compile the code in such a way that as soon as a function is entered the space for all local variables is immediately reserved. Even if some variable is only used in some conditional block, space for it will be reserved at the start of the function. That is why Stack Overflow errors happen only on entering new functions.\nHeap memory This is usually additional memory that you can request from the OS and this is the memory that you actually need to manage and properly release when no longer needed. It is used whenever you need to store and keep something, even when you return from some function where it is created or if it is too big to fit on the stack.\nWhen you get this memory what you actually have is a pointer to the first address within it and how much after that address is available. Some languages such as Zig represent those two things as one thing called a slice. You can read more about Zig slices here.\nAnyway it is up to you now how you want to interpret that memory. Is it one integer or an array of integers, or maybe a float, a character or some structure. In zig you can use one of these\n1 2 std.mem.bytesAsValue(comptime T: type, bytes: anytype) std.mem.bytesToValue(comptime T: type, bytes: anytype) to interpret the given array of bytes as a given T type.\nIf you are coming from object oriented and garbage collected language you might know that whenever you call new SomeClass() the memory for that object is allocated and that object is created but you can not imagine how you could control where and how it takes that memory. What the language does for you is actually allocate memory for the data of that class, casts the pointer it gets to the type of that class, then calls your constructor function and returns you that casted pointer. As you can see you can easily do so yourself with just a struct and some function that initializes the fields of that struct like a constructor would. Of course, unlike GC langauges you might also need to manually release that memory when you no longer need it.\nNow calling the OS whenever you need a few bytes of memory would ruin your performance because system calls are expensive. That is why languages usually come with some sort of Allocators.\nLesson 3: Allocators Allocators reserve more memory from the system than you currently need so they actually manage a pool of memory that you can then efficiently borrow from whenever you need it. C only comes with malloc which is a general purpose allocator but zig comes with more options.\nGeneral purpose allocator needs to try and be efficient no matter how you use it. Do you allocate a lot of small objects or big ones or a mix of both, do you free often or rare, in small chunks or in bulk. They also have to handle memory fragmentation.\nIf you imagine memory as a row of bytes where allocation reserves some of those bytes and freeing it makes those bytes available for future use you can also imagine how after some usage there might be a lot of little boxes that are available for use in between boxes that are still in use. Now if you want to allocate something bigger there might be enough total free bytes but none of the boxes might be big enough individually. That means your memory is fragmented and a lot of it becomes unusable.\nBecause of all of that general purpose allocators are the most complicated and often less efficient than specialized allocators tailored for each use.\nOne example is ArenaAllocator. It doesn’t support freeing individual allocations at all. The idea is that you use it within a part of your program which does some processing and needs to do a number of allocations none of which will be needed once the processing is complete. That way that part of the program can just allocate things and not think about freeing them and once the processing is complete you can just call ‘free everything’ on the ArenaAllocator itself. It is initialized with another allocator from which the actual allocating and freeing is done.\nYet another is FixedBufferAllocator. It is initialized with a limited array of bytes that you want to be served as memory from it. If the process then tries to allocate more memory from it than that array contains it will get an error. It is useful to make sure parts of the program don’t accidentally allocate more than they should or that they don’t leak memory. It is also useful because you can initialize it with a local array that is on the stack and pass that as an allocator to some library. You can only do this if the library has documented how much maximum memory it will need to do its job and if that amount can fit on the stack. This way the actual allocation it does through that allocator will be as cheap as possible and plus after its job is done all the memory is guaranteed to be freed.\nYou can also use StackFallbackAllocator with a certain size, which will under the hood use a FixedBufferAllocator on stack while the allocations fit in the given size and then start using a provided fallback allocator for the rest of allocations.\nSome others are PageAllocator which always allocates whole pages from the OS, which are usually 4KiB in size and LoggingAllocator that can log each allocation that happens through it.\nNow with just these you now have a lot of tools in your arsenal you can play with.\nExamples Compiler Compilers usually work in multiple passes. Each pass goes through data from the previous pass and generates new or modifies existing data. Input for the first pass is of course a code file which can also be thought of as a long string that needs to be parsed.\nAs each pass works it will need to allocate some temporary memory for its operation. For that purpose it is best to allocate one block big enough to fit estimated temporary allocations of each pass, maybe through PageAllocator and then make one FixedBufferAllocator over that memory that you will call the reset() on after each pass. That will simply make the whole buffer it uses ready to be used from start for the next pass thus reusing that initial allocation for each pass. It will also limit the temporary memory each pass can take so you can detect memory leaks earlier.\nFor the things that one pass generates for the next to use it might be best to use ArenaAllocator. That way if there is a pass in the pipeline that generates completely new data from the previous ones you can just call deinit() on that allocator to free all the memory allocated from previous passes at once.\nEither way the memory that you need all the way until the end of the compiling process probably doesn’t need to be manually freed at all since the compiler process will shutdown when it is finished and the OS will clean up all its memory anyway.\nImage loader If you are writing a lib that needs to parse some file formats like png or jpg and return parsed pixels it is best to allow the users to pass in the allocator that should be used. The catch is that besides allocating space for resulting data the lib might need to allocate some temporary memory for processing. It could just use the same allocator and in that case the best practice would be to first allocate the space for the result and then start allocating and freeing the temporary data. That way you minimize the possibility for fragmenting memory.\nIf you can guarantee the temporary space needed no matter the image size then you can internally make a FixedBufferAllocator that will also quickly catch if you by mistake miss that target. If the amount is also small you can just define a local array on the stack to serve as a backing buffer for that allocator. Otherwise you would probably allocate the buffer from the given allocator.\nThird option could be that you allow the user to pass in an additional allocator for temporary allocations. It is best if you at least make it optional if you don’t expect users will need that level of customization often. You can still internally combine the methods above with that allocator.\nConclusion Hopefully with just these two examples you can see that memory management can often be made very simple. Also solving the issue of memory can be an interesting pursuit of simplicity and flexibility.\nAlso note that although the principles described here should be applicable to any system programming language each of them will have its own quirks, especially C and C++. The zig is the first language I know that was designed not to have a globally accessible allocator, for example, which forces you to be deliberate about your allocations and this post was written with it in mind.\nIf you want to learn more and practice, I strongly suggest you try the Zig language. Try to solve some of the issues you worked on in the past using this language and its conventions and see how much fun you find along the way ;).\n","description":"","tags":["zig","programming","memory"],"title":"Basics of Allocating and Using Memory","uri":"/blog/basics-of-allocating-and-using-memory/"},{"content":"","description":"","tags":null,"title":"memory","uri":"/tags/memory/"},{"content":"","description":"","tags":null,"title":"csharp","uri":"/tags/csharp/"},{"content":"There are often situations where logging can affect performance. It is probably rare in the server world but it comes quite often when we try to log stuff in our Unity game. There its effect can be quite visible.\nThat is why, so far, we disabled all logger calls in our production builds by using a [Conditional(\"USE_LOGGING\")] attribute on logger methods and not defining the USE_LOGGER symbol in the build. You can read about that attribute here.\nBut our project grew and grew and at one point became complex enough that we had to reconsider. We needed an option to leave the logging lines in the code but have them disabled by default unless the backend server tells the game to enable some log levels for some tags. So the logging line would look something like this:\n1 2 3 4 5 // logger instance is created somewhere with some // specific tag that it will add for each log line // The call then looks like this: logger.Info($\"User {userId} from {cityName} logged in on {logInTime}.\"); The code inside that method would check if Info level is enabled for that logger’s tag and wouldn’t log the message if it isn’t. Here we were still concerned that the string interpolations would create enough garbage for the Garbage Collector that its cleanups would again slow down our game. Now, if you did any C# programming you will now be thinking: “Why are you using string interpolations? That is not how you should use the logger API. You should pass in a format string in arguments separately.”. You would be right, but it also doesn’t really stop you from using it that way. Also there is already a lot of code in our 7 years old project that uses code like this. Even if we did it the “correct” way it would still need to execute code that generates the values for arguments and to possibly box those arguments only to then conclude it doesn’t need any of that inside the method because logs are disabled for that tag and level.\nThe best solution we found online is a great Zero Allocation Logger. It also avoids boxing of parameters by having many overloads for logging methods with different number of generic parameters. It would still require that we refactor our huge code base never to use string interpolation and the api still expects string as a first parameter so it can’t force the developer not to use string interpolation.\nIn the end we did some measurements and concluded that impact isn’t as bad as we thought so we will try to just roll with what we have. But then I had a…\nBrilliant Idea So, from performance standpoint it would be ideal if our developers wouldn’t hate to always type:\n1 2 3 if (logger.IsEnabledFor(LogLevel.Info)) { logger.Info($\"User {userId} from {cityName} logged in on {logInTime}.\"); } But of course they do. Not just to type but also to read. There comes my brilliant idea. What if Info is a property instead of a method and that property returns an optional struct that has the Log() method. Then the usage would look like this:\n1 logger.Info?.Log($\"User {userId} is starting a match {matchId} with {injuredNum} injured players.\"); This is much less painful to type and read. If the logging is disabled the property will return null and the part after ?. will not be executed at all. On the other hand if it is enabled it will return the struct which doesn’t allocate any memory on the heap. If you accidentally try to call the .Log() method without ?. you will get a compile error.\nIf we wanted to convert all our log calls to this we could just execute Regex search and replace a few times.\nWe haven’t yet tried to put this idea into practice but it felt too cool not to share immediately.\n","description":"","tags":["programming","csharp"],"title":"Optimal Logging API for C#","uri":"/blog/optimal-logging-api-for-csharp/"},{"content":"","description":"","tags":null,"title":"png","uri":"/tags/png/"},{"content":"Although there is already a solid zigimg image loading library it didn’t quite tick all the checkboxes for me. It doesn’t provide the flexibility that I am aiming for and it is using far more allocations than is necessary. Also since I already wrote a png reader in DLang it felt like a good project for learning zig to try to reimplement it and try to improve on my original design.\nYou can find the solution I came up with here. In order to understand my design we first need to know a bit about the png format. The Png file is a sequence of chunks of different types. Each chunk has a 4 byte id, represented as 4 ascii letters. Some examples are:\nIHDR for a header chunk that contains things like width, height and pixel format PLTE for a palette chunk in case pixels are stored as indices into that palette tRNS for a chunk that says what color should be considered as transparent The specification says that if the first letter of the id is upper case it is a critical chunk that the reader must know how to parse. Otherwise the chunk is optional and the image can be displayed without parsing it but it might not be displayed completely as intended.\nSo my idea was to create a reader that can parse critical chunks and allow users to register parsers for any number of optional chunks. It would also come with some chunk parsers implemented but in such a way that they are not even compiled in if they are not used. I didn’t quite manage to accomplish that in the first version I wrote in DLang but I am pretty happy with what I managed to write so far in Zig.\nThis is the API I came up with so far:\n1 2 3 4 const file = try cwd.openFile(\"image.png\", .{ .mode = .read_only }); var reader = pngreader.fromFile(file); var header = try reader.loadHeader(); var pixelData = reader.loadWithHeader(\u0026header, allocator, options); In case you already have the whole file loaded into memory you can also use pngreader.fromMemory(u8buffer);. Also if you don’t want to handle the header separately but just load the image you can just call reader.load(allocator, options).\nThe key to the design is, of course, the options argument. Its type is defined like this:\n1 2 3 4 pub const ReaderOptions = struct { temp_allocator: Allocator, processors: []ReaderProcessor = \u0026[_]ReaderProcessor{}, }; It provides a way for you to specify a separate allocator that will be used for temporary allocations during loading and it is bounded to 800KiB at the moment but I hope to reduce it in the future. The other thing is a slice of processors for different chunk types. Each ReaderProcessor has an id which says what chunk type it is dedicated to and it provides processChunk and optional processPalette and processDataRow functions. It is actually an interface to specific implementation just like Allocator struct represents a common interface for different implementations of allocators. You can register a processor for critical or optional chunk but in case of optional chunks it will be a responsibility of its processChunk function to read in or seek over the bytes of its chunk from underlining stream reader while for critical chunks it must not do that but just use the passed in data. The other two methods allow each processor to affect the palette or pixel data as they are loaded using the info they parsed.\nCurrently the reader comes with two processors implemented: TrnsProcessor and PlteProcessor.\nTrnsProcessor will parse the tRNS chunk if it exists and extract what colors should be considered transparent. It will then add an alpha channel to the image format and place that info there. So if the image is in Grayscale format it will become GrayscaleAlpha and if it is in RGB format it will become RGBA and in the alpha channel 0 will be written for a color that needs to be considered transparent and 255 for others.\nPlteProcessor, if the image is in Indexed format will change that to RGB format and will convert pixel data so that instead of palette indices it contains the actual RGB values from the palette directly. Note that if you also use TrnsProcessor and the tRNS chunk also exists the final format will be RGBA since it will also add an alpha channel.\nSo if you just pass a default for the options argument:\n1 var pixelData = reader.loadWithHeader(\u0026header, allocator, .{}); no processors will be used or compiled in and a static buffer on stack will be used for temporary allocations. If you want to use default options that include the above two processors you can just do this:\n1 2 var def_options = DefOptions{}; var pixelData = reader.loadWithHeader(\u0026header, allocator, def_options.get()); It will also use a stack buffer for temporary allocations but it will use both of the above processors.\nIn case you implement additional processors, for example for sRGB and cHRM chunks you could call it with them like this:\n1 2 3 4 5 6 7 8 9 10 11 12 13 var trns = TrnsProcessor{}; var plte = PlteProcessor{}; var srgb = SrgbProcessor{}; var chrm = ChrmProcessor{}; var processors = [_]ReaderProcessor{ trns.processor(), plte.processor(), srgb.processor(), chrm.processor(), }; var tmp_buffer: [800 * 1024]u8 = undefined; var fb_allocator = std.heap.FixedBufferAllocator.init(tmp_buffer[0..]); var options = ReaderOptions.initWithProcessors(fb_allocator.allocator(), processors[0..]); Also if you want to use these as default throughout your project you can just define a struct called DefPngOptions in your root file in the same way DefOptions struct is defined in the reader.\nThe API for non default options is a bit verbose because you need to provide the place for all the pieces. In the above case they are all on stack. On the other hand I made default usage as simple as I could and I also provided more flexibility than any other png loader I found without sacrificing its memory efficiency or performance.\nI hope to cover a bit about how I handle the memory in a separate post. Until then happy Zigging!\n","description":"","tags":["zig","png","programming"],"title":"Png Reader in Zig","uri":"/blog/png-reader-in-zig/"},{"content":"","description":"","tags":null,"title":"engine","uri":"/tags/engine/"},{"content":"","description":"","tags":null,"title":"game","uri":"/tags/game/"},{"content":"I am doing programming for 24 years now and I don’t see myself getting bored with it. There is always one more thing to learn or to solve and I really want to know everything .\nThe goal I am most interested in is making my own game engine. But I don’t want to take the SDL library, some image and 3D data loading library and just write rendering logic. I want to learn how it all works.\nI want to know how windowing is done on different platforms, how inputs are processed, how sound is produced, how images or sounds or 3D models are parsed and loaded. I want to know every little thing that comes on the way.\nI don’t care that I will never get done. I don’t care if in 10 years I am still scratching the surface. As long as I am learning something new I am happy.\nObstacles I do have to confess it is easy to get sidetracked. I want to write the png loader, but for that I need a decompression library which needs an Adler hashing algorithm. I would check if there are good implementations of those in the language I am working on but if for any reason I am not happy about that implementation or I find someone wrote a better one in another language I want to port that or write a new one that is to my liking.\nSometimes I realize I am not happy with the language I chose so I would investigate others until I find a new pet. Or if I don’t find anything at the moment I might even try to write a compiler for my own language. At some point I also realize the path I took doesn’t hold my interest any more so I would go back and just choose some other path. Something interesting to learn is everywhere.\nIt also surprised me how often the things I learned turned out useful in my job even though I chose my hobbies to be different. On the other hand, I specifically chose not to go into making my own operating system. It would be too much removed from my daily work and I do have my limits.\nBesides all of this I always have motivation to play some games or watch movies or read books but about that some other time.\n","description":"","tags":["personal","game","engine"],"title":"How do I stay motivated","uri":"/blog/how-do-i-stay-motivated/"},{"content":"","description":"","tags":null,"title":"personal","uri":"/tags/personal/"},{"content":"","description":"","tags":null,"title":"Blog","uri":"/blog/"},{"content":"\nWhat is the closest thing in this world to magic?\nTo me it will always be programming. You type in some incantations and stuff happens .\nHere I want to document and share my explorations into this magic world. My most recent trip went into Zig land so most of the articles will talk about that.\nBut who am I? I got my first PC in 1997, when I was 13 years old and I got my hands on my first programming language somewhere in 1998. It was QBasic and I created some of the first games and programs in it. I wrote Hangman, Mastermind, Breakout and even did something like a Paint program.\nI shortly switched to Pascal and then jumped to Delphi (or Object Pascal). There I learned about the SDL library and OpenGL and made a clone of Nintendo’s Battle city game and 3D Rubik’s Cube solver.\nWhile doing that I realized how hard it is to create UI for a game, especially compared to Delphi which I consider is still unmatched in ease of use for creating desktop UIs. So, as I was finishing high school, I wrote a UI library called SDLControls for Object Pascal.\nDuring high school I also learned a bit about assembler and how CPUs work on a lower level. It was fascinating at the time.\nAs college started I lost my free time and didn’t do much outside of school projects which included Pascal, C, Java, C# and PHP. Straight from college I started working on Java business software in 2007. During the next four years I would move from the first company, to the second and third until in 2011 I got a job at a startup gaming company. One of the first in my country.\nThe company was a success and 11 years later I am still working at Nordeus doing my dream job. Surprisingly, for my younger self it turned out not to be making games itself, but rather making tools for making games .\nI started on some web applications with PHP and Javascript and then moved to Unity and C#. But that fascination about the inner workings of the PC from younger days is still burning in me so I still find some side projects to play with in my free time.\nCasey Muratory with his Handmade Hero series series and Jonathan Blow with his talks about a custom compiler were a great inspiration. Thanks to them I refreshed my C knowledge and wrote a tiny compiler, Summus, as a sort of introduction to writing one using LLVM as a backend.\nI then learned what I could about other new languages and among Rust, Go, Nim and DLang I chose the latter as the most intuitive and powerful language. Coming from Unity and C# DLang seemed like a perfect language for a Game Engine. It supports garbage collection but also manual memory management so it seemed like I could use it to write both low level systems and later use it as gameplay logic language as well. No need for separate scripting language.\nUnfortunately I got disappointed with some drawbacks of the language and the fact that its leadership didn’t seem very interested to work on those things. At the time Odin and Zig also came under my radar and so I decided to play with Zig and document my journey here.\nAnd so here we are!\n","description":"","tags":null,"title":"About Me","uri":"/more/about-me/"},{"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/"}]